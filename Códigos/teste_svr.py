# -*- coding: utf-8 -*-
"""teste_SVR.ipynb

Automatically generated by Colaboratory.

"""

from sklearn.datasets import fetch_20newsgroups
from sklearn.svm import SVR
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import nltk 
from nltk.corpus import stopwords 
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))

categories = ['alt.atheism', 'talk.religion.misc',
              'comp.graphics', 'sci.space']
categories2 = ['alt.atheism']
newsgroups_train = fetch_20newsgroups(subset='train',
                                     categories=categories,
                                     remove=('headers', 'footers', 'quotes'))

newsgroups_test = fetch_20newsgroups(subset='test',
                                     categories=categories,
                                     remove=('headers', 'footers', 'quotes'))


svc = SVR(kernel ='linear')
list_1 = []
vectorizer = TfidfVectorizer(stop_words = stop_words)
counter =0
for target in newsgroups_test.target:
  if target == 2:
      list_1.append(counter)
  counter = counter + 1

counter =0

vectors = vectorizer.fit_transform(newsgroups_train.data) # features
targets = newsgroups_train.target

vectors_test = vectorizer.transform(newsgroups_test.data)
print("Todos os documentos do tipo 2:")
print(list_1)
svc.fit(vectors, targets)
pred = svc.predict(vectors_test)
high = []
counter = 0
for a in pred:
  if a>1.99 and a<2.00:
    high.append(counter)
  counter = counter + 1
counter = 0
for h in high:
  if h in list_1:
    counter = counter + 1
print("Documentos com pontuaÃ§Ã£o alta:")
print(high)
print("Total de documentos achados:")
print(len(high))
print("Total de documentos achados que pertencem ao tipo 2:")
print(counter)
aux = counter
counter = counter / len(high)
print("PrecisÃ£o: ")
print(counter)
aux = aux / len(list_1)
print("Recall: ")
print (aux)
